{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.express as px\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = px.data.iris() # iris is a pandas DataFrame\n",
    "species = dict(df.filter(items=['species_id', 'species']).drop_duplicates().values)\n",
    "df = df.drop(['species'], axis=1)\n",
    "\n",
    "# normalization\n",
    "df.iloc[:,0:-1] = df.iloc[:,0:-1].apply(lambda x: (x-x.mean())/ x.std(), axis=0)\n",
    "\n",
    "train=df.sample(frac=0.7, random_state=777)\n",
    "test=df.drop(train.index)\n",
    "\n",
    "X = train[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].values\n",
    "Y = train['species_id']\n",
    "\n",
    "# one-hot encoding\n",
    "Y = np.squeeze(np.eye(len(species))[np.array(Y)-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,) (3,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m layers \u001b[39m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     FCLayer(in_size\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], out_size\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, activation_function\u001b[39m=\u001b[39mReLU()), \n\u001b[0;32m      3\u001b[0m     FCLayer(in_size\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, out_size\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, activation_function\u001b[39m=\u001b[39mReLU()), \n\u001b[0;32m      4\u001b[0m     FCLayer(in_size\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, out_size\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(species), activation_function\u001b[39m=\u001b[39mReLU())\n\u001b[0;32m      5\u001b[0m ]\n\u001b[0;32m      6\u001b[0m nn \u001b[39m=\u001b[39m NeuralNetwork(layers)\n\u001b[1;32m----> 8\u001b[0m costs \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mtrain(X, Y)\n\u001b[0;32m     10\u001b[0m fig \u001b[39m=\u001b[39m px\u001b[39m.\u001b[39mline(x\u001b[39m=\u001b[39mcosts[:, \u001b[39m0\u001b[39m], y\u001b[39m=\u001b[39mcosts[:, \u001b[39m1\u001b[39m], labels\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mEpoch\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mTotal Loss\u001b[39m\u001b[39m'\u001b[39m}, log_x\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m fig\u001b[39m.\u001b[39mshow()\n",
      "Cell \u001b[1;32mIn[3], line 39\u001b[0m, in \u001b[0;36mNeuralNetwork.train\u001b[1;34m(self, x, y, stochastic)\u001b[0m\n\u001b[0;32m     37\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx\n\u001b[0;32m     38\u001b[0m     cost \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pass()\n\u001b[1;32m---> 39\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_layers(cost, x)\n\u001b[0;32m     41\u001b[0m \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     42\u001b[0m     costs\u001b[39m.\u001b[39mappend([epoch, cost])\n",
      "Cell \u001b[1;32mIn[3], line 48\u001b[0m, in \u001b[0;36mNeuralNetwork._update_layers\u001b[1;34m(self, cost, x)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_layers\u001b[39m(\u001b[39mself\u001b[39m, cost, x):\n\u001b[0;32m     47\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 48\u001b[0m         layer\u001b[39m.\u001b[39;49mupdate_parameters(cost, x)\n",
      "Cell \u001b[1;32mIn[3], line 90\u001b[0m, in \u001b[0;36mFCLayer.update_parameters\u001b[1;34m(self, cost, x, alpha)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_parameters\u001b[39m(\u001b[39mself\u001b[39m, cost, x, alpha\u001b[39m=\u001b[39m\u001b[39m0.05\u001b[39m):\n\u001b[1;32m---> 90\u001b[0m     del_w, del_b \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gradient(cost, x)\n\u001b[0;32m     91\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweigth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m del_w \u001b[39m*\u001b[39m alpha\n\u001b[0;32m     92\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m del_b \u001b[39m*\u001b[39m alpha\n",
      "Cell \u001b[1;32mIn[3], line 95\u001b[0m, in \u001b[0;36mFCLayer._gradient\u001b[1;34m(self, cost, x)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_gradient\u001b[39m(\u001b[39mself\u001b[39m, cost, x):\n\u001b[1;32m---> 95\u001b[0m     del_w \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39msum(x \u001b[39m*\u001b[39;49m cost, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \n\u001b[0;32m     96\u001b[0m     del_b \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39msum(cost)\n\u001b[0;32m     98\u001b[0m     \u001b[39mreturn\u001b[39;00m del_w, del_b\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,) (3,) "
     ]
    }
   ],
   "source": [
    "layers = [\n",
    "    FCLayer(in_size=X.shape[1], out_size=5, activation_function=ReLU()), \n",
    "    FCLayer(in_size=5, out_size=5, activation_function=ReLU()), \n",
    "    FCLayer(in_size=5, out_size=len(species), activation_function=ReLU())\n",
    "]\n",
    "nn = NeuralNetwork(layers)\n",
    "\n",
    "costs = nn.train(X, Y)\n",
    "\n",
    "fig = px.line(x=costs[:, 0], y=costs[:, 1], labels={'x': 'Epoch', 'y':'Total Loss'}, log_x=True)\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].values\n",
    "Y_test = test['species_id']\n",
    "\n",
    "# one-hot encoding\n",
    "Y_test = np.squeeze(np.eye(len(species))[np.array(Y_test)-1])\n",
    "\n",
    "predicted = nn.predict(X_test)\n",
    "diff = (Y_test - predicted) ** 2\n",
    "diff.sum() / len(Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
